{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d397743d-e24d-4a46-9732-0a90b73ff903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 0. Imports and Setup\n",
    "# -------------------------------\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1a4afd9-898a-4ca7-a6bd-d5a255dda273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf7f4007-898e-4367-8f7e-117942719925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 1. Data Loading and Frame Extraction\n",
    "# -------------------------------\n",
    "def load_annotations(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    label_map = {'truthful': 0, 'deceptive': 1}\n",
    "    df['label'] = df['class'].map(label_map)\n",
    "    return df\n",
    "\n",
    "def extract_frames(video_path, max_frames=30, resize=(224, 224)):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while len(frames) < max_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = cv2.resize(frame, resize)\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    return frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa4f5bf1-d201-45f6-ab23-fb11a282bd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 2. Feature Extractor (MobileNetV2)\n",
    "# -------------------------------\n",
    "class FeatureExtractor:\n",
    "    def __init__(self, device='cuda'):\n",
    "        self.device = device\n",
    "        mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "        self.model = mobilenet.features\n",
    "        self.model.eval().to(device)\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def extract(self, video_path, max_frames=30):\n",
    "        frames = extract_frames(video_path, max_frames)\n",
    "        features = []\n",
    "        for frame in frames:\n",
    "            input_tensor = self.transform(frame).unsqueeze(0).to(self.device)\n",
    "            with torch.no_grad():\n",
    "                feat = self.model(input_tensor)\n",
    "                feat = torch.mean(feat, dim=[2, 3])\n",
    "            features.append(feat.squeeze(0).cpu().numpy())\n",
    "        return np.stack(features)\n",
    "\n",
    "def cache_features(df, video_dir, cache_dir, max_frames=30):\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    extractor = FeatureExtractor(device)\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        video_name = row['id']\n",
    "        cache_path = os.path.join(cache_dir, video_name.replace('.mp4', '.npy'))\n",
    "\n",
    "        if not os.path.exists(cache_path):\n",
    "            folder = 'Truthful' if row['label'] == 0 else 'Deceptive'\n",
    "            video_path = os.path.join(video_dir, folder, video_name)\n",
    "            try:\n",
    "                features = extractor.extract(video_path, max_frames)\n",
    "                np.save(cache_path, features)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {video_name}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c644f646-a638-478a-a336-23683e8d4c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 3. Dataset and DataLoader\n",
    "# -------------------------------\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, df, cache_dir, max_frames=30):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.cache_dir = cache_dir\n",
    "        self.max_frames = max_frames\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        video_name = row['id'].replace('.mp4', '.npy')\n",
    "        features_path = os.path.join(self.cache_dir, video_name)\n",
    "\n",
    "        try:\n",
    "            features = np.load(features_path)\n",
    "        except:\n",
    "            features = np.zeros((self.max_frames, 1280))\n",
    "\n",
    "        if len(features) > self.max_frames:\n",
    "            features = features[:self.max_frames]\n",
    "        elif len(features) < self.max_frames:\n",
    "            pad = np.zeros((self.max_frames - len(features), features.shape[1]))\n",
    "            features = np.vstack([features, pad])\n",
    "\n",
    "        return torch.FloatTensor(features), torch.tensor(row['label'], dtype=torch.float32)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    features, labels = zip(*batch)\n",
    "    features = torch.stack(features)\n",
    "    labels = torch.stack(labels)\n",
    "    lengths = torch.tensor([len(f) for f in features], dtype=torch.long)\n",
    "    return features, labels, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5226474e-cb7b-4bc7-a797-a6044853d294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -------------------------------\n",
    "# # 4. Model: CNN + BLSTM\n",
    "# # -------------------------------\n",
    "# class EnhancedCNNBLSTM(nn.Module):\n",
    "#     def __init__(self, input_size=1280, hidden_size=512, num_layers=3, dropout=0.5):\n",
    "#         super().__init__()\n",
    "#         self.feature_reducer = nn.Sequential(\n",
    "#             nn.Linear(input_size, 512),\n",
    "#             nn.ReLU()\n",
    "#         )\n",
    "\n",
    "#         self.blstm = nn.LSTM(\n",
    "#             input_size=512,\n",
    "#             hidden_size=hidden_size,\n",
    "#             num_layers=num_layers,\n",
    "#             bidirectional=True,\n",
    "#             batch_first=True,\n",
    "#             dropout=dropout\n",
    "#         )\n",
    "#         self.lstm_norm = nn.LayerNorm(hidden_size * 2)\n",
    "\n",
    "#         self.attention = nn.Sequential(\n",
    "#             nn.Linear(hidden_size * 2, hidden_size),\n",
    "#             nn.Tanh(),\n",
    "#             nn.Linear(hidden_size, 1, bias=False)\n",
    "#         )\n",
    "\n",
    "#         self.temporal_cnn = nn.Sequential(\n",
    "#             nn.Conv1d(hidden_size * 2, hidden_size, kernel_size=5, padding=2),\n",
    "#             nn.BatchNorm1d(hidden_size),\n",
    "#             nn.GELU(),\n",
    "#             nn.Dropout(dropout),\n",
    "#             nn.Conv1d(hidden_size, hidden_size // 2, kernel_size=3, padding=1),\n",
    "#             nn.BatchNorm1d(hidden_size // 2),\n",
    "#             nn.GELU(),\n",
    "#             nn.AdaptiveAvgPool1d(1)\n",
    "#         )\n",
    "\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Linear(hidden_size // 2, 256),\n",
    "#             nn.GELU(),\n",
    "#             nn.Dropout(dropout),\n",
    "#             nn.LayerNorm(256),\n",
    "#             nn.Linear(256, 1)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x, lengths):\n",
    "#         x = self.feature_reducer(x)\n",
    "#         packed = nn.utils.rnn.pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "#         packed_out, _ = self.blstm(packed)\n",
    "#         out, _ = nn.utils.rnn.pad_packed_sequence(packed_out, batch_first=True)\n",
    "\n",
    "#         attn_weights = F.softmax(self.attention(out), dim=1)\n",
    "#         out = torch.sum(attn_weights * out, dim=1)\n",
    "#         out = self.lstm_norm(out)\n",
    "\n",
    "#         out = out.unsqueeze(-1)\n",
    "#         out = self.temporal_cnn(out).squeeze(-1)\n",
    "\n",
    "#         return self.classifier(out).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64535242-9d89-41f3-b5cb-6cc6eb7ab748",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_BiLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, cnn_out_channels, cnn_kernel_size, lstm_hidden_size,\n",
    "                 lstm_num_layers, fc_hidden_size, dropout_rate, bidirectional=True):\n",
    "        super(CNN_BiLSTM, self).__init__()\n",
    "        \n",
    "        # 1D CNN expects input of shape (batch, channels=input_dim, sequence_len)\n",
    "        self.cnn = nn.Conv1d(in_channels=input_dim,\n",
    "                             out_channels=cnn_out_channels,\n",
    "                             kernel_size=cnn_kernel_size,\n",
    "                             padding=cnn_kernel_size // 2)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=cnn_out_channels,\n",
    "                            hidden_size=lstm_hidden_size,\n",
    "                            num_layers=lstm_num_layers,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=bidirectional)\n",
    "\n",
    "        self.bn = nn.BatchNorm1d(cnn_out_channels)\n",
    "\n",
    "        lstm_output_dim = lstm_hidden_size * (2 if bidirectional else 1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(lstm_output_dim, fc_hidden_size)\n",
    "        self.fc2 = nn.Linear(fc_hidden_size, 1)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # x: (batch_size, seq_len, input_dim)\n",
    "        x = x.permute(0, 2, 1)  # (batch_size, input_dim, seq_len)\n",
    "        x = self.bn(self.cnn(x))  # (batch_size, cnn_out_channels, seq_len)\n",
    "        x = x.permute(0, 2, 1)  # (batch_size, seq_len, cnn_out_channels)\n",
    "\n",
    "        # Optional: Adjust lengths if CNN changes time dim\n",
    "        # Skipped here because padding preserves length\n",
    "\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_out, _ = self.lstm(packed)\n",
    "        lstm_out, _ = nn.utils.rnn.pad_packed_sequence(packed_out, batch_first=True)\n",
    "\n",
    "        out, _ = torch.max(lstm_out, dim=1)  # (batch_size, lstm_output_dim)\n",
    "\n",
    "        out = self.dropout(self.fc1(out))\n",
    "        out = self.fc2(out).squeeze(1)     # (batch_size,)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a045ebf-f6a4-45b1-bc3a-42c21b405259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 5. Training & Evaluation\n",
    "# -------------------------------\n",
    "def train_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for features, labels, lengths in loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features, lengths)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for features, labels, lengths in loader:\n",
    "            features = features.to(device)\n",
    "            outputs = model(features, lengths)\n",
    "            preds = torch.sigmoid(outputs).cpu().numpy() > 0.5\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.numpy())\n",
    "    return {\n",
    "        'accuracy': accuracy_score(all_labels, all_preds),\n",
    "        'precision': precision_score(all_labels, all_preds),\n",
    "        'recall': recall_score(all_labels, all_preds),\n",
    "        'f1': f1_score(all_labels, all_preds)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3276dd7-e317-4351-b551-707d6f63e9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from optuna) (23.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from optuna) (2.0.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from optuna) (6.0.1)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
      "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
      "   ---------------------------------------- 0.0/386.6 kB ? eta -:--:--\n",
      "   ------- -------------------------------- 71.7/386.6 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 386.6/386.6 kB 4.8 MB/s eta 0:00:00\n",
      "Downloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
      "   ---------------------------------------- 0.0/231.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 231.9/231.9 kB 7.2 MB/s eta 0:00:00\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.5/78.5 kB 4.6 MB/s eta 0:00:00\n",
      "Installing collected packages: Mako, colorlog, alembic, optuna\n",
      "Successfully installed Mako-1.3.10 alembic-1.15.2 colorlog-6.9.0 optuna-4.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "baf93810-d42c-43e9-b5e7-6d18c979505b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters to optimize\n",
    "    params = {\n",
    "        'cnn_out_channels': trial.suggest_categorical('cnn_out_channels', [64, 128, 256]),\n",
    "        'cnn_kernel_size': trial.suggest_int('cnn_kernel_size', 3, 7, step=2),\n",
    "        'lstm_hidden_size': trial.suggest_categorical('lstm_hidden_size', [128, 256, 512]),\n",
    "        'lstm_num_layers': trial.suggest_int('lstm_num_layers', 1, 3),\n",
    "        'fc_hidden_size': trial.suggest_categorical('fc_hidden_size', [64, 128, 256]),\n",
    "        'dropout_rate': trial.suggest_float('dropout_rate', 0.3, 0.7, step=0.1),\n",
    "        'lr': trial.suggest_float('lr', 1e-5, 1e-4, log=True),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [8, 16, 32])\n",
    "    }\n",
    "    \n",
    "    # Create model with trial parameters\n",
    "    model = CNN_BiLSTM(\n",
    "        input_dim=1280,\n",
    "        cnn_out_channels=params['cnn_out_channels'],\n",
    "        cnn_kernel_size=params['cnn_kernel_size'],\n",
    "        lstm_hidden_size=params['lstm_hidden_size'],\n",
    "        lstm_num_layers=params['lstm_num_layers'],\n",
    "        fc_hidden_size=params['fc_hidden_size'],\n",
    "        dropout_rate=params['dropout_rate'],\n",
    "        bidirectional=True\n",
    "    ).to(device)\n",
    "    \n",
    "    # Create data loader with trial batch size\n",
    "    train_loader = DataLoader(\n",
    "        VideoDataset(train_df, cache_dir, max_frames),\n",
    "        batch_size=params['batch_size'],\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    \n",
    "    # Optimizer and scheduler\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=params['lr'],\n",
    "        weight_decay=1e-5\n",
    "    )\n",
    "    \n",
    "    # Training loop (shortened for tuning)\n",
    "    for epoch in range(10):  # Fewer epochs for tuning\n",
    "        train_epoch(model, train_loader, optimizer, criterion)\n",
    "        metrics = evaluate(model, val_loader)\n",
    "        \n",
    "        # Report intermediate results\n",
    "        trial.report(metrics['f1'], epoch)\n",
    "        \n",
    "        # Handle pruning (early stopping)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "    \n",
    "    return metrics['f1']\n",
    "\n",
    "def run_hyperparameter_tuning():\n",
    "    study = optuna.create_study(\n",
    "        direction='maximize',\n",
    "        pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=3)\n",
    "    )\n",
    "    study.optimize(objective, n_trials=30, timeout=3600)\n",
    "    \n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(f\"  F1-score: {trial.value}\")\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "    \n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "330ae6ed-78c9-40b1-abe0-991e17aafc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayush\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ayush\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [00:00<00:00, 16669.26it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 5994.00it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 12453.40it/s]\n",
      "[I 2025-05-07 11:59:24,409] A new study created in memory with name: no-name-e3e70e3b-17f5-45d3-9126-f6fcb8ad8a76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter optimization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 11:59:26,846] Trial 0 finished with value: 0.2857142857142857 and parameters: {'cnn_out_channels': 256, 'cnn_kernel_size': 3, 'lstm_hidden_size': 128, 'lstm_num_layers': 1, 'fc_hidden_size': 256, 'dropout_rate': 0.5, 'lr': 1.1691403620341307e-05, 'batch_size': 32}. Best is trial 0 with value: 0.2857142857142857.\n",
      "[I 2025-05-07 11:59:32,182] Trial 1 finished with value: 0.7692307692307692 and parameters: {'cnn_out_channels': 64, 'cnn_kernel_size': 5, 'lstm_hidden_size': 256, 'lstm_num_layers': 2, 'fc_hidden_size': 256, 'dropout_rate': 0.7, 'lr': 3.0246073668859985e-05, 'batch_size': 32}. Best is trial 1 with value: 0.7692307692307692.\n",
      "[I 2025-05-07 11:59:36,762] Trial 2 finished with value: 0.7692307692307692 and parameters: {'cnn_out_channels': 64, 'cnn_kernel_size': 3, 'lstm_hidden_size': 128, 'lstm_num_layers': 2, 'fc_hidden_size': 128, 'dropout_rate': 0.7, 'lr': 6.0527705831770484e-05, 'batch_size': 16}. Best is trial 1 with value: 0.7692307692307692.\n",
      "[I 2025-05-07 11:59:43,794] Trial 3 finished with value: 0.7058823529411764 and parameters: {'cnn_out_channels': 64, 'cnn_kernel_size': 3, 'lstm_hidden_size': 256, 'lstm_num_layers': 3, 'fc_hidden_size': 64, 'dropout_rate': 0.3, 'lr': 3.997861277201292e-05, 'batch_size': 32}. Best is trial 1 with value: 0.7692307692307692.\n",
      "[I 2025-05-07 11:59:50,816] Trial 4 finished with value: 0.8333333333333334 and parameters: {'cnn_out_channels': 256, 'cnn_kernel_size': 7, 'lstm_hidden_size': 256, 'lstm_num_layers': 1, 'fc_hidden_size': 256, 'dropout_rate': 0.5, 'lr': 2.8179533049874422e-05, 'batch_size': 8}. Best is trial 4 with value: 0.8333333333333334.\n",
      "C:\\Users\\ayush\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ayush\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2025-05-07 11:59:56,620] Trial 5 pruned. \n",
      "[I 2025-05-07 11:59:58,016] Trial 6 pruned. \n",
      "[I 2025-05-07 12:00:08,545] Trial 7 finished with value: 0.6666666666666666 and parameters: {'cnn_out_channels': 128, 'cnn_kernel_size': 7, 'lstm_hidden_size': 512, 'lstm_num_layers': 1, 'fc_hidden_size': 128, 'dropout_rate': 0.6000000000000001, 'lr': 4.597122850114334e-05, 'batch_size': 8}. Best is trial 4 with value: 0.8333333333333334.\n",
      "C:\\Users\\ayush\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ayush\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ayush\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2025-05-07 12:00:10,908] Trial 8 pruned. \n",
      "[I 2025-05-07 12:00:12,111] Trial 9 pruned. \n",
      "[I 2025-05-07 12:00:19,581] Trial 10 finished with value: 0.7692307692307692 and parameters: {'cnn_out_channels': 256, 'cnn_kernel_size': 7, 'lstm_hidden_size': 256, 'lstm_num_layers': 1, 'fc_hidden_size': 256, 'dropout_rate': 0.4, 'lr': 1.6128040734340494e-05, 'batch_size': 8}. Best is trial 4 with value: 0.8333333333333334.\n",
      "[I 2025-05-07 12:00:31,426] Trial 11 finished with value: 0.8333333333333334 and parameters: {'cnn_out_channels': 256, 'cnn_kernel_size': 5, 'lstm_hidden_size': 256, 'lstm_num_layers': 2, 'fc_hidden_size': 256, 'dropout_rate': 0.7, 'lr': 2.3366297842930298e-05, 'batch_size': 8}. Best is trial 4 with value: 0.8333333333333334.\n",
      "C:\\Users\\ayush\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2025-05-07 12:00:36,332] Trial 12 pruned. \n",
      "[I 2025-05-07 12:00:42,795] Trial 13 pruned. \n",
      "[I 2025-05-07 12:00:47,337] Trial 14 pruned. \n",
      "[I 2025-05-07 12:00:51,010] Trial 15 pruned. \n",
      "[I 2025-05-07 12:01:07,473] Trial 16 pruned. \n",
      "[I 2025-05-07 12:01:13,478] Trial 17 pruned. \n",
      "[I 2025-05-07 12:01:16,799] Trial 18 pruned. \n",
      "[I 2025-05-07 12:01:25,728] Trial 19 pruned. \n",
      "[I 2025-05-07 12:01:31,973] Trial 20 pruned. \n",
      "[I 2025-05-07 12:01:34,169] Trial 21 pruned. \n",
      "[I 2025-05-07 12:01:36,347] Trial 22 pruned. \n",
      "C:\\Users\\ayush\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ayush\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ayush\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ayush\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2025-05-07 12:01:38,691] Trial 23 pruned. \n",
      "[I 2025-05-07 12:01:43,005] Trial 24 pruned. \n",
      "[I 2025-05-07 12:01:44,118] Trial 25 pruned. \n",
      "[I 2025-05-07 12:01:52,969] Trial 26 pruned. \n",
      "C:\\Users\\ayush\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2025-05-07 12:01:58,000] Trial 27 pruned. \n",
      "[I 2025-05-07 12:02:00,905] Trial 28 pruned. \n",
      "[I 2025-05-07 12:02:02,525] Trial 29 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  F1-score: 0.8333333333333334\n",
      "  Params: \n",
      "    cnn_out_channels: 256\n",
      "    cnn_kernel_size: 7\n",
      "    lstm_hidden_size: 256\n",
      "    lstm_num_layers: 1\n",
      "    fc_hidden_size: 256\n",
      "    dropout_rate: 0.5\n",
      "    lr: 2.8179533049874422e-05\n",
      "    batch_size: 8\n",
      "\n",
      "Training final model with best parameters...\n",
      "Epoch 1: Loss=0.6802 | Val Acc=0.5833 | F1=0.2857\n",
      "Epoch 2: Loss=0.6432 | Val Acc=0.6667 | F1=0.6000\n",
      "Epoch 3: Loss=0.5922 | Val Acc=0.7500 | F1=0.7273\n",
      "Epoch 4: Loss=0.5572 | Val Acc=0.7500 | F1=0.7692\n",
      "Epoch 5: Loss=0.5274 | Val Acc=0.7500 | F1=0.7692\n",
      "Epoch 6: Loss=0.4974 | Val Acc=0.7500 | F1=0.7692\n",
      "Epoch 7: Loss=0.4786 | Val Acc=0.7500 | F1=0.7692\n",
      "Epoch 8: Loss=0.4692 | Val Acc=0.7500 | F1=0.7692\n",
      "Epoch 9: Loss=0.4484 | Val Acc=0.7500 | F1=0.7692\n",
      "Epoch 10: Loss=0.4506 | Val Acc=0.7500 | F1=0.7692\n",
      "Epoch 11: Loss=0.4874 | Val Acc=0.7500 | F1=0.7692\n",
      "Epoch 12: Loss=0.4272 | Val Acc=0.7500 | F1=0.7692\n",
      "Epoch 13: Loss=0.3883 | Val Acc=0.7500 | F1=0.7692\n",
      "Epoch 14: Loss=0.3367 | Val Acc=0.7500 | F1=0.7692\n",
      "Epoch 15: Loss=0.3104 | Val Acc=0.7500 | F1=0.7692\n",
      "Epoch 16: Loss=0.3007 | Val Acc=0.7500 | F1=0.7692\n",
      "Epoch 17: Loss=0.3265 | Val Acc=0.7500 | F1=0.7692\n",
      "Epoch 18: Loss=0.2588 | Val Acc=0.7500 | F1=0.7692\n",
      "Epoch 19: Loss=0.2744 | Val Acc=0.7500 | F1=0.7692\n",
      "Epoch 20: Loss=0.2601 | Val Acc=0.7500 | F1=0.7692\n",
      "Final Evaluation on Test Set:\n",
      "{'accuracy': 0.88, 'precision': 0.8571428571428571, 'recall': 0.9230769230769231, 'f1': 0.888888888888889}\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 6. Full Pipeline Entry Point\n",
    "# -------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load and split dataset\n",
    "    annotations = load_annotations(\"data/annotations.csv\")\n",
    "    train_df, test_df = train_test_split(annotations, test_size=0.2, stratify=annotations['label'], random_state=42)\n",
    "    train_df, val_df = train_test_split(train_df, test_size=0.125, stratify=train_df['label'], random_state=42)\n",
    "\n",
    "    video_dir = \"data/Clips\"\n",
    "    cache_dir = \"cached_features\"\n",
    "    max_frames = 30\n",
    "\n",
    "    # Cache features if not already\n",
    "    print(\"Caching features...\")\n",
    "    cache_features(train_df, video_dir, cache_dir, max_frames)\n",
    "    cache_features(val_df, video_dir, cache_dir, max_frames)\n",
    "    cache_features(test_df, video_dir, cache_dir, max_frames)\n",
    "\n",
    "    # Run hyperparameter tuning first\n",
    "    print(\"Starting hyperparameter optimization...\")\n",
    "    best_params = run_hyperparameter_tuning()\n",
    "    \n",
    "    # Now run main training with best params\n",
    "    print(\"\\nTraining final model with best parameters...\")\n",
    "    model = CNN_BiLSTM(\n",
    "        input_dim=1280,\n",
    "        cnn_out_channels=best_params['cnn_out_channels'],\n",
    "        cnn_kernel_size=best_params['cnn_kernel_size'],\n",
    "        lstm_hidden_size=best_params['lstm_hidden_size'],\n",
    "        lstm_num_layers=best_params['lstm_num_layers'],\n",
    "        fc_hidden_size=best_params['fc_hidden_size'],\n",
    "        dropout_rate=best_params['dropout_rate'],\n",
    "        bidirectional=True\n",
    "    ).to(device)\n",
    "    \n",
    "    # DataLoaders\n",
    "    # train_loader = DataLoader(VideoDataset(train_df, cache_dir, max_frames), batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
    "    # val_loader = DataLoader(VideoDataset(val_df, cache_dir, max_frames), batch_size=16, shuffle=False, collate_fn=collate_fn)\n",
    "    # test_loader = DataLoader(VideoDataset(test_df, cache_dir, max_frames), batch_size=16, shuffle=False, collate_fn=collate_fn)\n",
    "    # Now create data loaders using best batch sizes\n",
    "    train_loader = DataLoader(\n",
    "        VideoDataset(train_df, cache_dir, max_frames),\n",
    "        batch_size=best_params['batch_size'],\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        VideoDataset(val_df, cache_dir, max_frames),\n",
    "        batch_size=best_params['batch_size'],  # Could use different val batch size if desired\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        VideoDataset(test_df, cache_dir, max_frames),\n",
    "        batch_size=best_params['batch_size'],  # Could use different test batch size\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    # Initialize CNN-BiLSTM model\n",
    "    model = CNN_BiLSTM(\n",
    "        input_dim=1280,\n",
    "        cnn_out_channels=best_params['cnn_out_channels'],\n",
    "        cnn_kernel_size=best_params['cnn_kernel_size'],\n",
    "        lstm_hidden_size=best_params['lstm_hidden_size'],\n",
    "        lstm_num_layers=best_params['lstm_num_layers'],\n",
    "        fc_hidden_size=best_params['fc_hidden_size'],\n",
    "        dropout_rate=best_params['dropout_rate'],\n",
    "        bidirectional=True\n",
    "    ).to(device)\n",
    "\n",
    "    # Optimizer with weight decay\n",
    "    # optimizer = torch.optim.AdamW(\n",
    "    #     model.parameters(),\n",
    "    #     lr=5e-5,           # Reduced from 1e-4 (prevent overshooting)\n",
    "    #     weight_decay=1e-5\n",
    "    # )\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=best_params['lr'],\n",
    "        weight_decay=1e-5\n",
    "    )\n",
    "\n",
    "    # Optional: compute class imbalance for pos_weight\n",
    "    pos_weight = torch.tensor([\n",
    "        len(train_df[train_df['label']==0]) / \n",
    "        len(train_df[train_df['label']==1])\n",
    "    ], device=device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    # criterion = FocalLoss()\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer,\n",
    "        T_0=10,            # Reset every 10 epochs\n",
    "        eta_min=1e-6        # Min learning rate\n",
    "    )\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(20):\n",
    "        loss = train_epoch(model, train_loader, optimizer, criterion)\n",
    "        scheduler.step()\n",
    "        metrics = evaluate(model, val_loader)\n",
    "        print(f\"Epoch {epoch+1}: Loss={loss:.4f} | Val Acc={metrics['accuracy']:.4f} | F1={metrics['f1']:.4f}\")\n",
    "\n",
    "    # Final test evaluation\n",
    "    print(\"Final Evaluation on Test Set:\")\n",
    "    test_metrics = evaluate(model, test_loader)\n",
    "    print(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96702af3-ee8b-4ccc-a2f8-fa0928ecda9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set distribution:\n",
      "class\n",
      "truthful     42\n",
      "deceptive    42\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Validation set distribution:\n",
      "class\n",
      "truthful     6\n",
      "deceptive    6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test set distribution:\n",
      "class\n",
      "deceptive    13\n",
      "truthful     12\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set distribution:\")\n",
    "print(train_df['class'].value_counts())\n",
    "\n",
    "print(\"\\nValidation set distribution:\")\n",
    "print(val_df['class'].value_counts())\n",
    "\n",
    "print(\"\\nTest set distribution:\")\n",
    "print(test_df['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c537b94f-e70d-4cad-bb7c-99f144037396",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
